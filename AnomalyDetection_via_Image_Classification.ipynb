{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125973 [00:00<?, ?it/s]C:\\Anaconda\\envs\\tensorflow-cpu\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 125973/125973 [1:01:06<00:00, 34.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label images\n",
      "0      0       \n",
      "1      0  1.jpg\n",
      "2      1  2.jpg\n",
      "3      0  3.jpg\n",
      "4      0  4.jpg\n"
     ]
    }
   ],
   "source": [
    "filename = \"new_train_labels.csv\"\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv(filename, encoding='utf-8')\n",
    "\n",
    "df[\"images\"]=\"\"\n",
    "from tqdm import tqdm \n",
    "for i in tqdm(range(len(df))):\n",
    "    if i == 0: \n",
    "        continue\n",
    "    df[\"images\"][i] = str(i)+\".jpg\"\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125968</th>\n",
       "      <td>1</td>\n",
       "      <td>125968.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>0</td>\n",
       "      <td>125969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>0</td>\n",
       "      <td>125970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125971</th>\n",
       "      <td>1</td>\n",
       "      <td>125971.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>0</td>\n",
       "      <td>125972.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label      images\n",
       "125968      1  125968.jpg\n",
       "125969      0  125969.jpg\n",
       "125970      0  125970.jpg\n",
       "125971      1  125971.jpg\n",
       "125972      0  125972.jpg"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125973/125973 [00:01<00:00, 68455.20it/s]\n",
      "100%|██████████| 125972/125972 [05:27<00:00, 439.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125972, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "imagefiles_list = []\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    if i == 0: \n",
    "        continue\n",
    "    imagefiles_list.append(df['images'][i])\n",
    "    \n",
    "size = (8,8)\n",
    "x = np.array([np.array(Image.open(\"./img_data_rev/img_data/\"+fname).resize(size).convert('RGB')) for fname in tqdm(imagefiles_list)])\n",
    "print(x.shape)\n",
    "\n",
    "x.dump(\"train_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125972,)\n"
     ]
    }
   ],
   "source": [
    "#labels = pd.get_dummies(df[\"label\"][1:]).as_matrix()\n",
    "import numpy as np\n",
    "labels = df[\"label\"][1:].as_matrix()\n",
    "print(labels.shape)\n",
    "labels.dump(\"train_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\tensorflow-cpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Anaconda\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          1792      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 133,121\n",
      "Trainable params: 133,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Conv2D,MaxPooling2D, Flatten\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import backend as K\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import time\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "import h5py\n",
    "\n",
    "X_train = np.load(\"train_features.pkl\")\n",
    "Y_train = np.load(\"train_labels.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "cnn2d_1 = Sequential([Conv2D(64, (3,3), padding=\"same\",input_shape=(8,8,3)),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1),\n",
    "    Activation('sigmoid'),\n",
    "])\n",
    "print(cnn2d_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/22544 [00:00<?, ?it/s]\n",
      "  3%|▎         | 608/22544 [00:00<00:03, 6036.00it/s]\n",
      "  5%|▌         | 1232/22544 [00:00<00:03, 6082.76it/s]\n",
      "  8%|▊         | 1842/22544 [00:00<00:03, 6074.63it/s]\n",
      " 11%|█         | 2461/22544 [00:00<00:03, 6095.60it/s]\n",
      " 14%|█▍        | 3113/22544 [00:00<00:03, 6204.06it/s]\n",
      " 17%|█▋        | 3739/22544 [00:00<00:03, 6207.19it/s]\n",
      " 19%|█▉        | 4382/22544 [00:00<00:02, 6258.90it/s]\n",
      " 22%|██▏       | 5021/22544 [00:00<00:02, 6284.20it/s]\n",
      " 25%|██▌       | 5674/22544 [00:00<00:02, 6342.46it/s]\n",
      " 28%|██▊       | 6329/22544 [00:01<00:02, 6389.63it/s]\n",
      " 31%|███       | 6985/22544 [00:01<00:02, 6425.20it/s]\n",
      " 34%|███▍      | 7639/22544 [00:01<00:02, 6446.03it/s]\n",
      " 37%|███▋      | 8293/22544 [00:01<00:02, 6459.92it/s]\n",
      " 40%|███▉      | 8944/22544 [00:01<00:02, 6460.77it/s]\n",
      " 43%|████▎     | 9612/22544 [00:01<00:01, 6511.08it/s]\n",
      " 46%|████▌     | 10263/22544 [00:01<00:01, 6496.51it/s]\n",
      " 49%|████▊     | 10950/22544 [00:01<00:01, 6590.34it/s]\n",
      " 52%|█████▏    | 11621/22544 [00:01<00:01, 6611.48it/s]\n",
      " 54%|█████▍    | 12282/22544 [00:01<00:01, 6576.92it/s]\n",
      " 57%|█████▋    | 12956/22544 [00:02<00:01, 6610.80it/s]\n",
      " 60%|██████    | 13633/22544 [00:02<00:01, 6643.44it/s]\n",
      " 63%|██████▎   | 14311/22544 [00:02<00:01, 6669.40it/s]\n",
      " 67%|██████▋   | 14996/22544 [00:02<00:01, 6707.40it/s]\n",
      " 70%|██████▉   | 15681/22544 [00:02<00:01, 6734.98it/s]\n",
      " 73%|███████▎  | 16385/22544 [00:02<00:00, 6809.97it/s]\n",
      " 76%|███████▌  | 17067/22544 [00:02<00:00, 6757.77it/s]\n",
      " 79%|███████▊  | 17744/22544 [00:02<00:00, 6686.86it/s]\n",
      " 82%|████████▏ | 18458/22544 [00:02<00:00, 6802.43it/s]\n",
      " 85%|████████▍ | 19139/22544 [00:02<00:00, 6789.79it/s]\n",
      " 88%|████████▊ | 19847/22544 [00:03<00:00, 6859.74it/s]\n",
      " 91%|█████████ | 20556/22544 [00:03<00:00, 6912.42it/s]\n",
      " 94%|█████████▍| 21248/22544 [00:03<00:00, 6838.37it/s]\n",
      " 97%|█████████▋| 21937/22544 [00:03<00:00, 6838.86it/s]\n",
      "100%|██████████| 22544/22544 [00:03<00:00, 6588.25it/s]\n",
      "  0%|          | 0/22544 [00:00<?, ?it/s]\n",
      " 30%|██▉       | 6762/22544 [00:00<00:00, 67130.47it/s]\n",
      " 59%|█████▉    | 13322/22544 [00:00<00:00, 66513.59it/s]\n",
      " 87%|████████▋ | 19635/22544 [00:00<00:00, 65292.20it/s]\n",
      "100%|██████████| 22544/22544 [00:00<00:00, 64564.59it/s]\n",
      "  0%|          | 0/22543 [00:00<?, ?it/s]\n",
      "  2%|▏         | 384/22543 [00:00<00:05, 3811.27it/s]\n",
      "  3%|▎         | 781/22543 [00:00<00:05, 3849.29it/s]\n",
      "  5%|▌         | 1192/22543 [00:00<00:05, 3915.81it/s]\n",
      "  7%|▋         | 1595/22543 [00:00<00:05, 3940.87it/s]\n",
      "  9%|▉         | 1998/22543 [00:00<00:05, 3958.94it/s]\n",
      " 11%|█         | 2407/22543 [00:00<00:05, 3988.59it/s]\n",
      " 12%|█▏        | 2796/22543 [00:00<00:04, 3949.84it/s]\n",
      " 14%|█▍        | 3206/22543 [00:00<00:04, 3985.00it/s]\n",
      " 16%|█▌        | 3609/22543 [00:00<00:04, 3989.77it/s]\n",
      " 18%|█▊        | 4025/22543 [00:01<00:04, 4030.71it/s]\n",
      " 20%|█▉        | 4431/22543 [00:01<00:04, 4031.14it/s]\n",
      " 21%|██▏       | 4827/22543 [00:01<00:04, 3976.61it/s]\n",
      " 23%|██▎       | 5228/22543 [00:01<00:04, 3977.47it/s]\n",
      " 25%|██▌       | 5645/22543 [00:01<00:04, 4024.85it/s]\n",
      " 27%|██▋       | 6059/22543 [00:01<00:04, 4049.99it/s]\n",
      " 29%|██▊       | 6476/22543 [00:01<00:03, 4076.45it/s]\n",
      " 31%|███       | 6883/22543 [00:01<00:03, 4065.66it/s]\n",
      " 32%|███▏      | 7289/22543 [00:01<00:03, 4019.08it/s]\n",
      " 34%|███▍      | 7704/22543 [00:01<00:03, 4048.70it/s]\n",
      " 36%|███▌      | 8109/22543 [00:02<00:03, 4040.47it/s]\n",
      " 38%|███▊      | 8513/22543 [00:02<00:03, 4031.32it/s]\n",
      " 40%|███▉      | 8917/22543 [00:02<00:03, 4001.17it/s]\n",
      " 41%|████▏     | 9322/22543 [00:02<00:03, 4007.06it/s]\n",
      " 43%|████▎     | 9723/22543 [00:02<00:03, 3905.98it/s]\n",
      " 45%|████▍     | 10115/22543 [00:02<00:03, 3724.50it/s]\n",
      " 47%|████▋     | 10490/22543 [00:02<00:03, 3626.62it/s]\n",
      " 48%|████▊     | 10855/22543 [00:02<00:03, 3617.22it/s]\n",
      " 50%|████▉     | 11248/22543 [00:02<00:03, 3698.26it/s]\n",
      " 52%|█████▏    | 11648/22543 [00:02<00:02, 3775.89it/s]\n",
      " 54%|█████▎    | 12067/22543 [00:03<00:02, 3883.70it/s]\n",
      " 55%|█████▌    | 12465/22543 [00:03<00:02, 3903.71it/s]\n",
      " 57%|█████▋    | 12868/22543 [00:03<00:02, 3931.89it/s]\n",
      " 59%|█████▉    | 13279/22543 [00:03<00:02, 3975.66it/s]\n",
      " 61%|██████    | 13684/22543 [00:03<00:02, 3988.65it/s]\n",
      " 62%|██████▏   | 14084/22543 [00:03<00:02, 3936.63it/s]\n",
      " 64%|██████▍   | 14479/22543 [00:03<00:02, 3764.04it/s]\n",
      " 66%|██████▌   | 14858/22543 [00:03<00:02, 3582.62it/s]\n",
      " 68%|██████▊   | 15220/22543 [00:03<00:02, 3347.81it/s]\n",
      " 69%|██████▉   | 15561/22543 [00:04<00:02, 3262.81it/s]\n",
      " 71%|███████   | 15917/22543 [00:04<00:01, 3339.58it/s]\n",
      " 72%|███████▏  | 16270/22543 [00:04<00:01, 3387.53it/s]\n",
      " 74%|███████▍  | 16656/22543 [00:04<00:01, 3509.66it/s]\n",
      " 76%|███████▌  | 17061/22543 [00:04<00:01, 3648.77it/s]\n",
      " 77%|███████▋  | 17469/22543 [00:04<00:01, 3760.21it/s]\n",
      " 79%|███████▉  | 17871/22543 [00:04<00:01, 3827.01it/s]\n",
      " 81%|████████  | 18274/22543 [00:04<00:01, 3877.14it/s]\n",
      " 83%|████████▎ | 18677/22543 [00:04<00:00, 3913.81it/s]\n",
      " 85%|████████▍ | 19070/22543 [00:04<00:00, 3898.06it/s]\n",
      " 86%|████████▋ | 19468/22543 [00:05<00:00, 3914.28it/s]\n",
      " 88%|████████▊ | 19861/22543 [00:05<00:00, 3830.60it/s]\n",
      " 90%|████████▉ | 20245/22543 [00:05<00:00, 3735.96it/s]\n",
      " 91%|█████████▏| 20620/22543 [00:05<00:00, 3603.10it/s]\n",
      " 93%|█████████▎| 20983/22543 [00:05<00:00, 3372.99it/s]\n",
      " 95%|█████████▍| 21325/22543 [00:05<00:00, 3340.13it/s]\n",
      " 96%|█████████▌| 21697/22543 [00:05<00:00, 3438.71it/s]\n",
      " 98%|█████████▊| 22093/22543 [00:05<00:00, 3572.71it/s]\n",
      "100%|█████████▉| 22488/22543 [00:05<00:00, 3670.68it/s]\n",
      "100%|██████████| 22543/22543 [00:05<00:00, 3806.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22543, 8, 8, 3)\n",
      "(22544, 38)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test_labels.csv\", encoding='utf-8')\n",
    "test_df[\"images\"]=\"\"\n",
    "from tqdm import tqdm \n",
    "for i in tqdm(range(len(test_df))):\n",
    "    if i == 0: \n",
    "        continue\n",
    "    test_df[\"images\"][i] = str(i)+\".jpg\"\n",
    "test_imagefiles_list = []\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    if i == 0: \n",
    "        continue \n",
    "    test_imagefiles_list.append(test_df['images'][i])\n",
    "    \n",
    "size = (8,8)\n",
    "test_x = np.array([np.array(Image.open(\"./img_kddtest+/img_kddtest+/\"+fname).resize(size).convert('RGB')) for fname in tqdm(test_imagefiles_list)])\n",
    "print(test_x.shape)\n",
    "\n",
    "test_x.dump(\"test_features.pkl\")\n",
    "\n",
    "test_labels = pd.get_dummies(test_df[\"label\"]).as_matrix()\n",
    "\n",
    "print(test_labels.shape)\n",
    "test_labels.dump(\"test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125972/125972 [==============================] - 26s 208us/step - loss: 7.5023 - acc: 0.5345\n",
      "Epoch 2/10\n",
      "125972/125972 [==============================] - 25s 197us/step - loss: 7.5017 - acc: 0.5346\n",
      "Epoch 3/10\n",
      "125972/125972 [==============================] - 25s 195us/step - loss: 7.5017 - acc: 0.5346\n",
      "Epoch 4/10\n",
      "125972/125972 [==============================] - 25s 195us/step - loss: 7.5017 - acc: 0.5346\n",
      "Epoch 5/10\n",
      "125972/125972 [==============================] - 25s 196us/step - loss: 7.5017 - acc: 0.5346\n",
      "Epoch 6/10\n",
      "125972/125972 [==============================] - 25s 196us/step - loss: 7.5017 - acc: 0.5346\n",
      "Epoch 7/10\n",
      "125972/125972 [==============================] - 25s 195us/step - loss: 7.5017 - acc: 0.5346\n",
      "Epoch 8/10\n",
      "125972/125972 [==============================] - 24s 193us/step - loss: 7.5017 - acc: 0.5346\n",
      "Epoch 9/10\n",
      "125972/125972 [==============================] - 3469s 28ms/step - loss: 7.5017 - acc: 0.5346\n",
      "Epoch 10/10\n",
      "125972/125972 [==============================] - 53s 424us/step - loss: 7.5017 - acc: 0.5346\n",
      "Total time taken to train the Training model is 3721.249366760254\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "cnn2d_1.compile(loss='binary_crossentropy', optimizer=\"adam\",metrics=['accuracy'])\n",
    "# train\n",
    "start_time = time.time()\n",
    "history = cnn2d_1.fit(X_train, Y_train, batch_size=64,epochs=10)\n",
    "end_time = time.time() \n",
    "print(\"Total time taken to train the Training model is\", (end_time - start_time))\n",
    "# serialize model to JSON\n",
    "model_json = cnn2d_1.to_json()\n",
    "with open(\"NSL_KDD_Train.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "cnn2d_1.save_weights(\"NSL_KDD_Train_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Saved model to disk\")\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('Acc_Valaccuaracy00_01.png')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-cpu]",
   "language": "python",
   "name": "conda-env-tensorflow-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
