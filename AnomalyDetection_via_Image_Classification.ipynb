{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label\n",
       "0   normal\n",
       "1   normal\n",
       "2  neptune\n",
       "3   normal\n",
       "4   normal"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"train_labels.csv\"\n",
    "import pandas as pd \n",
    "df = pd.read_csv(filename, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125973/125973 [01:16<00:00, 1461.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label images\n",
      "0   normal       \n",
      "1   normal  1.jpg\n",
      "2  neptune  2.jpg\n",
      "3   normal  3.jpg\n",
      "4   normal  4.jpg\n"
     ]
    }
   ],
   "source": [
    "df[\"images\"]=\"\"\n",
    "from tqdm import tqdm \n",
    "for i in tqdm(range(len(df))):\n",
    "    if i == 0: \n",
    "        continue\n",
    "    df[\"images\"][i] = str(i)+\".jpg\"\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125968</th>\n",
       "      <td>neptune</td>\n",
       "      <td>125969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>normal</td>\n",
       "      <td>125970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>normal</td>\n",
       "      <td>125971.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125971</th>\n",
       "      <td>neptune</td>\n",
       "      <td>125972.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>normal</td>\n",
       "      <td>125973.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label      images\n",
       "125968  neptune  125969.jpg\n",
       "125969   normal  125970.jpg\n",
       "125970   normal  125971.jpg\n",
       "125971  neptune  125972.jpg\n",
       "125972   normal  125973.jpg"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125973/125973 [00:01<00:00, 68455.20it/s]\n",
      "100%|██████████| 125972/125972 [05:27<00:00, 439.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125972, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "imagefiles_list = []\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    if i == 0: \n",
    "        continue\n",
    "    imagefiles_list.append(df['images'][i])\n",
    "    \n",
    "size = (8,8)\n",
    "x = np.array([np.array(Image.open(\"./img_data_rev/img_data/\"+fname).resize(size).convert('RGB')) for fname in tqdm(imagefiles_list)])\n",
    "print(x.shape)\n",
    "\n",
    "x.dump(\"train_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1              normal\n",
       "2             neptune\n",
       "3              normal\n",
       "4              normal\n",
       "5             neptune\n",
       "6             neptune\n",
       "7             neptune\n",
       "8             neptune\n",
       "9             neptune\n",
       "10            neptune\n",
       "11            neptune\n",
       "12             normal\n",
       "13        warezclient\n",
       "14            neptune\n",
       "15            neptune\n",
       "16             normal\n",
       "17            ipsweep\n",
       "18             normal\n",
       "19             normal\n",
       "20            neptune\n",
       "21            neptune\n",
       "22             normal\n",
       "23             normal\n",
       "24            neptune\n",
       "25             normal\n",
       "26            neptune\n",
       "27             normal\n",
       "28             normal\n",
       "29             normal\n",
       "30            ipsweep\n",
       "             ...     \n",
       "125943         normal\n",
       "125944         normal\n",
       "125945         normal\n",
       "125946        neptune\n",
       "125947        ipsweep\n",
       "125948        neptune\n",
       "125949         normal\n",
       "125950       teardrop\n",
       "125951         normal\n",
       "125952         normal\n",
       "125953        neptune\n",
       "125954         normal\n",
       "125955         normal\n",
       "125956         normal\n",
       "125957         normal\n",
       "125958        neptune\n",
       "125959         normal\n",
       "125960         normal\n",
       "125961         normal\n",
       "125962         normal\n",
       "125963         normal\n",
       "125964        neptune\n",
       "125965         normal\n",
       "125966        neptune\n",
       "125967         normal\n",
       "125968        neptune\n",
       "125969         normal\n",
       "125970         normal\n",
       "125971        neptune\n",
       "125972         normal\n",
       "Name: label, Length: 125972, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125972, 23)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.get_dummies(df[\"label\"][1:]).as_matrix()\n",
    "\n",
    "print(labels.shape)\n",
    "labels.dump(\"train_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          1792      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 23)                2967      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 23)                0         \n",
      "=================================================================\n",
      "Total params: 135,959\n",
      "Trainable params: 135,959\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Conv2D,MaxPooling2D, Flatten\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import backend as K\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import time\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "import h5py\n",
    "\n",
    "X_train = np.load(\"train_features.pkl\")\n",
    "Y_train = np.load(\"train_labels.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "cnn2d_1 = Sequential([Conv2D(64, (3,3), padding=\"same\",input_shape=(8,8,3)),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(23),\n",
    "    Activation('sigmoid'),\n",
    "])\n",
    "print(cnn2d_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/22544 [00:00<?, ?it/s]\n",
      "  3%|▎         | 608/22544 [00:00<00:03, 6036.00it/s]\n",
      "  5%|▌         | 1232/22544 [00:00<00:03, 6082.76it/s]\n",
      "  8%|▊         | 1842/22544 [00:00<00:03, 6074.63it/s]\n",
      " 11%|█         | 2461/22544 [00:00<00:03, 6095.60it/s]\n",
      " 14%|█▍        | 3113/22544 [00:00<00:03, 6204.06it/s]\n",
      " 17%|█▋        | 3739/22544 [00:00<00:03, 6207.19it/s]\n",
      " 19%|█▉        | 4382/22544 [00:00<00:02, 6258.90it/s]\n",
      " 22%|██▏       | 5021/22544 [00:00<00:02, 6284.20it/s]\n",
      " 25%|██▌       | 5674/22544 [00:00<00:02, 6342.46it/s]\n",
      " 28%|██▊       | 6329/22544 [00:01<00:02, 6389.63it/s]\n",
      " 31%|███       | 6985/22544 [00:01<00:02, 6425.20it/s]\n",
      " 34%|███▍      | 7639/22544 [00:01<00:02, 6446.03it/s]\n",
      " 37%|███▋      | 8293/22544 [00:01<00:02, 6459.92it/s]\n",
      " 40%|███▉      | 8944/22544 [00:01<00:02, 6460.77it/s]\n",
      " 43%|████▎     | 9612/22544 [00:01<00:01, 6511.08it/s]\n",
      " 46%|████▌     | 10263/22544 [00:01<00:01, 6496.51it/s]\n",
      " 49%|████▊     | 10950/22544 [00:01<00:01, 6590.34it/s]\n",
      " 52%|█████▏    | 11621/22544 [00:01<00:01, 6611.48it/s]\n",
      " 54%|█████▍    | 12282/22544 [00:01<00:01, 6576.92it/s]\n",
      " 57%|█████▋    | 12956/22544 [00:02<00:01, 6610.80it/s]\n",
      " 60%|██████    | 13633/22544 [00:02<00:01, 6643.44it/s]\n",
      " 63%|██████▎   | 14311/22544 [00:02<00:01, 6669.40it/s]\n",
      " 67%|██████▋   | 14996/22544 [00:02<00:01, 6707.40it/s]\n",
      " 70%|██████▉   | 15681/22544 [00:02<00:01, 6734.98it/s]\n",
      " 73%|███████▎  | 16385/22544 [00:02<00:00, 6809.97it/s]\n",
      " 76%|███████▌  | 17067/22544 [00:02<00:00, 6757.77it/s]\n",
      " 79%|███████▊  | 17744/22544 [00:02<00:00, 6686.86it/s]\n",
      " 82%|████████▏ | 18458/22544 [00:02<00:00, 6802.43it/s]\n",
      " 85%|████████▍ | 19139/22544 [00:02<00:00, 6789.79it/s]\n",
      " 88%|████████▊ | 19847/22544 [00:03<00:00, 6859.74it/s]\n",
      " 91%|█████████ | 20556/22544 [00:03<00:00, 6912.42it/s]\n",
      " 94%|█████████▍| 21248/22544 [00:03<00:00, 6838.37it/s]\n",
      " 97%|█████████▋| 21937/22544 [00:03<00:00, 6838.86it/s]\n",
      "100%|██████████| 22544/22544 [00:03<00:00, 6588.25it/s]\n",
      "  0%|          | 0/22544 [00:00<?, ?it/s]\n",
      " 30%|██▉       | 6762/22544 [00:00<00:00, 67130.47it/s]\n",
      " 59%|█████▉    | 13322/22544 [00:00<00:00, 66513.59it/s]\n",
      " 87%|████████▋ | 19635/22544 [00:00<00:00, 65292.20it/s]\n",
      "100%|██████████| 22544/22544 [00:00<00:00, 64564.59it/s]\n",
      "  0%|          | 0/22543 [00:00<?, ?it/s]\n",
      "  2%|▏         | 384/22543 [00:00<00:05, 3811.27it/s]\n",
      "  3%|▎         | 781/22543 [00:00<00:05, 3849.29it/s]\n",
      "  5%|▌         | 1192/22543 [00:00<00:05, 3915.81it/s]\n",
      "  7%|▋         | 1595/22543 [00:00<00:05, 3940.87it/s]\n",
      "  9%|▉         | 1998/22543 [00:00<00:05, 3958.94it/s]\n",
      " 11%|█         | 2407/22543 [00:00<00:05, 3988.59it/s]\n",
      " 12%|█▏        | 2796/22543 [00:00<00:04, 3949.84it/s]\n",
      " 14%|█▍        | 3206/22543 [00:00<00:04, 3985.00it/s]\n",
      " 16%|█▌        | 3609/22543 [00:00<00:04, 3989.77it/s]\n",
      " 18%|█▊        | 4025/22543 [00:01<00:04, 4030.71it/s]\n",
      " 20%|█▉        | 4431/22543 [00:01<00:04, 4031.14it/s]\n",
      " 21%|██▏       | 4827/22543 [00:01<00:04, 3976.61it/s]\n",
      " 23%|██▎       | 5228/22543 [00:01<00:04, 3977.47it/s]\n",
      " 25%|██▌       | 5645/22543 [00:01<00:04, 4024.85it/s]\n",
      " 27%|██▋       | 6059/22543 [00:01<00:04, 4049.99it/s]\n",
      " 29%|██▊       | 6476/22543 [00:01<00:03, 4076.45it/s]\n",
      " 31%|███       | 6883/22543 [00:01<00:03, 4065.66it/s]\n",
      " 32%|███▏      | 7289/22543 [00:01<00:03, 4019.08it/s]\n",
      " 34%|███▍      | 7704/22543 [00:01<00:03, 4048.70it/s]\n",
      " 36%|███▌      | 8109/22543 [00:02<00:03, 4040.47it/s]\n",
      " 38%|███▊      | 8513/22543 [00:02<00:03, 4031.32it/s]\n",
      " 40%|███▉      | 8917/22543 [00:02<00:03, 4001.17it/s]\n",
      " 41%|████▏     | 9322/22543 [00:02<00:03, 4007.06it/s]\n",
      " 43%|████▎     | 9723/22543 [00:02<00:03, 3905.98it/s]\n",
      " 45%|████▍     | 10115/22543 [00:02<00:03, 3724.50it/s]\n",
      " 47%|████▋     | 10490/22543 [00:02<00:03, 3626.62it/s]\n",
      " 48%|████▊     | 10855/22543 [00:02<00:03, 3617.22it/s]\n",
      " 50%|████▉     | 11248/22543 [00:02<00:03, 3698.26it/s]\n",
      " 52%|█████▏    | 11648/22543 [00:02<00:02, 3775.89it/s]\n",
      " 54%|█████▎    | 12067/22543 [00:03<00:02, 3883.70it/s]\n",
      " 55%|█████▌    | 12465/22543 [00:03<00:02, 3903.71it/s]\n",
      " 57%|█████▋    | 12868/22543 [00:03<00:02, 3931.89it/s]\n",
      " 59%|█████▉    | 13279/22543 [00:03<00:02, 3975.66it/s]\n",
      " 61%|██████    | 13684/22543 [00:03<00:02, 3988.65it/s]\n",
      " 62%|██████▏   | 14084/22543 [00:03<00:02, 3936.63it/s]\n",
      " 64%|██████▍   | 14479/22543 [00:03<00:02, 3764.04it/s]\n",
      " 66%|██████▌   | 14858/22543 [00:03<00:02, 3582.62it/s]\n",
      " 68%|██████▊   | 15220/22543 [00:03<00:02, 3347.81it/s]\n",
      " 69%|██████▉   | 15561/22543 [00:04<00:02, 3262.81it/s]\n",
      " 71%|███████   | 15917/22543 [00:04<00:01, 3339.58it/s]\n",
      " 72%|███████▏  | 16270/22543 [00:04<00:01, 3387.53it/s]\n",
      " 74%|███████▍  | 16656/22543 [00:04<00:01, 3509.66it/s]\n",
      " 76%|███████▌  | 17061/22543 [00:04<00:01, 3648.77it/s]\n",
      " 77%|███████▋  | 17469/22543 [00:04<00:01, 3760.21it/s]\n",
      " 79%|███████▉  | 17871/22543 [00:04<00:01, 3827.01it/s]\n",
      " 81%|████████  | 18274/22543 [00:04<00:01, 3877.14it/s]\n",
      " 83%|████████▎ | 18677/22543 [00:04<00:00, 3913.81it/s]\n",
      " 85%|████████▍ | 19070/22543 [00:04<00:00, 3898.06it/s]\n",
      " 86%|████████▋ | 19468/22543 [00:05<00:00, 3914.28it/s]\n",
      " 88%|████████▊ | 19861/22543 [00:05<00:00, 3830.60it/s]\n",
      " 90%|████████▉ | 20245/22543 [00:05<00:00, 3735.96it/s]\n",
      " 91%|█████████▏| 20620/22543 [00:05<00:00, 3603.10it/s]\n",
      " 93%|█████████▎| 20983/22543 [00:05<00:00, 3372.99it/s]\n",
      " 95%|█████████▍| 21325/22543 [00:05<00:00, 3340.13it/s]\n",
      " 96%|█████████▌| 21697/22543 [00:05<00:00, 3438.71it/s]\n",
      " 98%|█████████▊| 22093/22543 [00:05<00:00, 3572.71it/s]\n",
      "100%|█████████▉| 22488/22543 [00:05<00:00, 3670.68it/s]\n",
      "100%|██████████| 22543/22543 [00:05<00:00, 3806.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22543, 8, 8, 3)\n",
      "(22544, 38)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test_labels.csv\", encoding='utf-8')\n",
    "test_df[\"images\"]=\"\"\n",
    "from tqdm import tqdm \n",
    "for i in tqdm(range(len(test_df))):\n",
    "    if i == 0: \n",
    "        continue\n",
    "    test_df[\"images\"][i] = str(i)+\".jpg\"\n",
    "test_imagefiles_list = []\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    if i == 0: \n",
    "        continue \n",
    "    test_imagefiles_list.append(test_df['images'][i])\n",
    "    \n",
    "size = (8,8)\n",
    "test_x = np.array([np.array(Image.open(\"./img_kddtest+/img_kddtest+/\"+fname).resize(size).convert('RGB')) for fname in tqdm(test_imagefiles_list)])\n",
    "print(test_x.shape)\n",
    "\n",
    "test_x.dump(\"test_features.pkl\")\n",
    "\n",
    "test_labels = pd.get_dummies(test_df[\"label\"]).as_matrix()\n",
    "\n",
    "print(test_labels.shape)\n",
    "test_labels.dump(\"test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125972/125972 [==============================] - 13s 100us/step - loss: 2.4671 - acc: 0.0304\n",
      "Epoch 2/10\n",
      "125972/125972 [==============================] - 12s 99us/step - loss: 2.4718 - acc: 0.0460\n",
      "Epoch 3/10\n",
      "125972/125972 [==============================] - 12s 98us/step - loss: 2.6962 - acc: 0.2469\n",
      "Epoch 4/10\n",
      "125972/125972 [==============================] - 12s 97us/step - loss: 2.8235 - acc: 0.3138\n",
      "Epoch 5/10\n",
      "125972/125972 [==============================] - 12s 96us/step - loss: 2.8262 - acc: 0.3261\n",
      "Epoch 6/10\n",
      "125972/125972 [==============================] - 12s 96us/step - loss: 2.8267 - acc: 0.3269\n",
      "Epoch 7/10\n",
      "125972/125972 [==============================] - 12s 96us/step - loss: 2.8267 - acc: 0.3268\n",
      "Epoch 8/10\n",
      "125972/125972 [==============================] - 12s 98us/step - loss: 2.8268 - acc: 0.3269\n",
      "Epoch 9/10\n",
      "125972/125972 [==============================] - 12s 99us/step - loss: 2.8267 - acc: 0.3268\n",
      "Epoch 10/10\n",
      "125972/125972 [==============================] - 12s 98us/step - loss: 2.8258 - acc: 0.3271\n",
      "Total time taken to train the Training model is 123.51782703399658\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cnn1d_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-feb25401a66c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# serialize weights to HDF5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcnn1d_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NSL_KDD_Train_weights.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cnn1d_1' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "cnn2d_1.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])\n",
    "# train\n",
    "start_time = time.time()\n",
    "history = cnn2d_1.fit(X_train, Y_train, batch_size=64,epochs=10)\n",
    "end_time = time.time() \n",
    "print(\"Total time taken to train the Training model is\", (end_time - start_time))\n",
    "# serialize model to JSON\n",
    "model_json = cnn2d_1.to_json()\n",
    "with open(\"NSL_KDD_Train.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "cnn1d_1.save_weights(\"NSL_KDD_Train_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Saved model to disk\")\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('Acc_Valaccuaracy00_01.png')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-cpu]",
   "language": "python",
   "name": "conda-env-tensorflow-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
